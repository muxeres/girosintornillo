{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4aa96b1",
   "metadata": {},
   "source": [
    "Notebook de debug: foco en segmentos PF/AGRO/PJ, caída de principalidade (últimos 3 meses), sin inadimplencia,\n",
    "análisis de caída de uso de tarjeta interno (últimos 3 meses, reducción >30%) y ejemplo JSON de contacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports y rutas\n",
    "import os, sys, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "user = os.getlogin()\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\{USER}\\Sicredi\\TimeBI_0730 - Documentos\\01_Rotineiros\\33_GiroCarteira\".format(USER=os.getlogin())\n",
    "PRINCIPALIDADE_PATH = os.path.join(BASE_DIR, \"indicador_nova_principalidade_historico.parquet\")\n",
    "EMI_CARTOES_PATH = os.path.join(BASE_DIR, \"emi_compras_confirmacao_historico.parquet\")  # nombre según su comentario\n",
    "INAD_PATH = os.path.join(r\"C:\\Users\\{USER}\\Sicredi\\TimeBI_0730 - Documentos\\_BASES\\arquivos_parquet\".format(USER=os.getlogin()), \"base_inadimplentes.parquet\")\n",
    "SAIDA_DIR = os.path.join(BASE_DIR, \"debug_output\")\n",
    "os.makedirs(SAIDA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos principales (principalidade)\n",
    "if not os.path.exists(PRINCIPALIDADE_PATH):\n",
    "    raise FileNotFoundError(PRINCIPALIDADE_PATH)\n",
    "principalidade = pd.read_parquet(PRINCIPALIDADE_PATH)\n",
    "\n",
    "# Asegurar columnas clave existan\n",
    "required = ['cpf_cnpj','ano_mes','pontos_principalidade','var_pontos','queda_flag','soma_quedas','sow_cartao','possui_cartao_credito']\n",
    "missing = [c for c in required if c not in principalidade.columns]\n",
    "if missing:\n",
    "    # continuar pero creando columnas vacías para permitir flujo de debug\n",
    "    for c in missing:\n",
    "        principalidade[c] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar histórico de operaciones con tarjetas (emi_compras_confirmacao_historico)\n",
    "# columnas esperadas: cpf_cnpj, marca, tpo_produto, dat_compra, funcionalidad, ano_mes, valor_compra (opcional)\n",
    "if os.path.exists(EMI_CARTOES_PATH):\n",
    "    emi = pd.read_parquet(EMI_CARTOES_PATH)\n",
    "else:\n",
    "    emi = pd.DataFrame(columns=['cpf_cnpj','marca','tpo_produto','dat_compra','funcionalidade','ano_mes','valor_compra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por segmentos que interesan y sin inadimplencia\n",
    "segments_target = ['PF','AGRO','PJ']\n",
    "principalidade['segmento'] = principalidade['segmento'].astype(str)\n",
    "df = principalidade[principalidade['segmento'].isin(segments_target)].copy()\n",
    "\n",
    "# Cargar base de inadimplentes si existe y excluir\n",
    "if os.path.exists(INAD_PATH):\n",
    "    inad = pd.read_parquet(INAD_PATH)\n",
    "    cand_cols = [c for c in inad.columns if 'cpf' in c.lower() or 'doc' in c.lower()]\n",
    "    if 'cpf_cnpj' not in inad.columns and cand_cols:\n",
    "        inad = inad.rename(columns={cand_cols[0]:'cpf_cnpj'})\n",
    "    inad['cpf_cnpj'] = inad['cpf_cnpj'].astype(str).str.replace(r'\\D','',regex=True).str.lstrip('0')\n",
    "    inad = inad[['cpf_cnpj']].drop_duplicates()\n",
    "    df['cpf_cnpj'] = df['cpf_cnpj'].astype(str).str.replace(r'\\D','',regex=True).str.lstrip('0')\n",
    "    df = df.merge(inad.assign(flag_inad=1), on='cpf_cnpj', how='left')\n",
    "    df = df[df['flag_inad'].isna()].copy()\n",
    "else:\n",
    "    df['flag_inad'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantener sólo registros con caída de principalidade en últimos 3 meses (soma_quedas >= 3)\n",
    "# Asumimos que 'soma_quedas' ya está calculada en principalidade; si no, usar var_pontos en ventana.\n",
    "df = df[df['soma_quedas'].fillna(0) >= 3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar uso de tarjeta interno en últimos 3 meses: calcular gasto/volumen por cliente por mes y medir caída %\n",
    "# Normalizar campos y filtrar por los meses relevantes presentes en df\n",
    "meses_obj = sorted(df['ano_mes'].dropna().unique())[-3:]  # últimos 3 meses según principalidade\n",
    "if not meses_obj:\n",
    "    meses_obj = sorted(principalidade['ano_mes'].dropna().unique())[-3:]\n",
    "\n",
    "emi['cpf_cnpj'] = emi['cpf_cnpj'].astype(str).str.replace(r'\\D','',regex=True).str.lstrip('0')\n",
    "emi['ano_mes'] = emi['ano_mes'].astype(str)\n",
    "\n",
    "# Definir criterio de \"tarjeta interna\": ejemplo: marca contiene 'SICREDI' o tpo_produto indica 'TARJETA'\n",
    "cond_interna = emi['marca'].astype(str).str.upper().fillna('').str.contains('SICREDI') | emi['tpo_produto'].astype(str).str.upper().fillna('').str.contains('TARJ')\n",
    "\n",
    "emi_filtro = emi[emi['ano_mes'].isin(meses_obj) & cond_interna].copy()\n",
    "\n",
    "# Agregar monto por cliente x mes (si no hay valor_compra se agrega conteo)\n",
    "if 'valor_compra' in emi_filtro.columns and emi_filtro['valor_compra'].notna().any():\n",
    "    agg = emi_filtro.groupby(['cpf_cnpj','ano_mes'])['valor_compra'].sum().reset_index()\n",
    "else:\n",
    "    agg = emi_filtro.groupby(['cpf_cnpj','ano_mes']).size().reset_index(name='valor_compra')\n",
    "\n",
    "# Pivotar meses para tener columnas m1,m2,m3 donde m3 es el mes más reciente\n",
    "agg_p = agg.pivot(index='cpf_cnpj', columns='ano_mes', values='valor_compra').fillna(0)\n",
    "meses_sorted = sorted([m for m in agg_p.columns])\n",
    "if len(meses_sorted) >= 3:\n",
    "    m1, m2, m3 = meses_sorted[-3], meses_sorted[-2], meses_sorted[-1]\n",
    "else:\n",
    "    # completar si faltan meses\n",
    "    m1 = meses_sorted[0] if meses_sorted else None\n",
    "    m2 = meses_sorted[1] if len(meses_sorted)>1 else m1\n",
    "    m3 = meses_sorted[-1] if meses_sorted else m1\n",
    "\n",
    "agg_p = agg_p.rename(columns={m1:'m1', m2:'m2', m3:'m3'}) if m1 is not None else agg_p\n",
    "agg_p = agg_p.reset_index().rename(columns={'index':'cpf_cnpj'}) if 'cpf_cnpj' not in agg_p.columns else agg_p.reset_index()\n",
    "# Calcular promedio de periodo anterior y caída %\n",
    "def calc_drop(row):\n",
    "    try:\n",
    "        prev = 0.0\n",
    "        if (('m1' in row.index) and ('m2' in row.index)):\n",
    "            prev = float((row.get('m1',0.0) + row.get('m2',0.0)) / (2 if pd.notnull(row.get('m2',None)) else 1))\n",
    "        cur = float(row.get('m3',0.0))\n",
    "        if prev == 0:\n",
    "            return np.nan\n",
    "        return (prev - cur) / prev\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "agg_p['card_drop_pct'] = agg_p.apply(calc_drop, axis=1)\n",
    "# Filtrar caída mayor 30% (0.30)\n",
    "agg_p['drop_flag_30'] = agg_p['card_drop_pct'] > 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir con df para tener contexto y rankear por caída % (descendente)\n",
    "agg_context = agg_p.merge(df[['cpf_cnpj','gestor','cod_agencia','sow_cartao']], on='cpf_cnpj', how='inner')\n",
    "agg_context = agg_context.sort_values('card_drop_pct', ascending=False)\n",
    "candidates_ranked = agg_context.copy()\n",
    "# Guardar snapshot de candidatos\n",
    "candidates_path = os.path.join(SAIDA_DIR, 'candidates_card_drop.parquet')\n",
    "candidates_ranked.to_parquet(candidates_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un ejemplo JSON de contacto para el primer candidato (si existe)\n",
    "example = None\n",
    "if not candidates_ranked.empty:\n",
    "    r = candidates_ranked.iloc[0].to_dict()\n",
    "    # Buscar datos de contacto en las fuentes disponibles (aquí se crea un ejemplo usando columnas esperadas)\n",
    "    contato = {\n",
    "        \"titulo\": f\"CONTATO DO DIA: {r.get('cpf_cnpj','')} - {r.get('cod_agencia',0)}\",\n",
    "        \"usuarioResponsavel\": r.get('gestor',''),\n",
    "        \"usuarioSolicitante\": r.get('gestor',''),\n",
    "        \"numeroAgencia\": int(r.get('cod_agencia') or 0),\n",
    "        \"descricao\": (\n",
    "            f\"Segmento: {r.get('tipo_pessoa','')} | Soma quedas: {r.get('soma_quedas','')}. \"\n",
    "            f\"Drop cartão interno (pct): {r.get('card_drop_pct'):.2f} | Produtos básicos faltantes: (ver base). \"\n",
    "            \"Ofertar: Conta Easy PF / Recuperar productos perdidos. \"\n",
    "            \"Contactos: traer teléfonos y emails desde fuentes de contacto.\"\n",
    "        ),\n",
    "        \"statusChamado\": \"A FAZER\",\n",
    "        \"departamentoId\": 0,\n",
    "        \"nomeDepartamento\": None,\n",
    "        \"dataNecessidade\": (datetime.today().date() + timedelta(days=15)).isoformat() + \"T00:00:00.000Z\",\n",
    "        \"categoriaChamado\": \"Giro de Carteira\"\n",
    "    }\n",
    "    example = contato\n",
    "# guardar ejemplo en JSON si existe\n",
    "if example is not None:\n",
    "    ex_path = os.path.join(SAIDA_DIR, 'example_contact.json')\n",
    "    pd.Series([example]).to_json(ex_path, force_ascii=False, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec36cb",
   "metadata": {},
   "source": [
    "Siguientes pasos sugeridos:\n",
    "- Validar nombres exactos de columnas en emi_compras_confirmacao_historico y ajustar cond_interna si la marca/tpo_produto usan otra nomenclatura.  \n",
    "- Determinar las 3 agencias piloto y añadir filtro por cod_agencia.  \n",
    "- Ajustar la regla de ranking para usar % caída del uso del cartão interno exactamente como se defina (ticket medio vs volumen).  \n",
    "- Integrar campos de contacto (teléfonos/email) desde la base de associados para completar \"descricao\" con datos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source 'C:/Users/carola_luco/Sicredi/TimeBI_0730 - Documentos/01_Rotineiros/33_GiroCarteira/giro_de_carteira/bbmfiltros.py': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m principalidade \u001b[38;5;241m=\u001b[39m  \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mrf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSicredi\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTimeBI_0730 - Documentos\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m01_Rotineiros\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m33_GiroCarteira\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgiro_de_carteira\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    667\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parquet.py:265\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    259\u001b[0m     path,\n\u001b[0;32m    260\u001b[0m     filesystem,\n\u001b[0;32m    261\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    262\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    263\u001b[0m )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[0;32m    274\u001b[0m         filterwarnings(\n\u001b[0;32m    275\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    276\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake_block is deprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    278\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1811\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[0;32m   1799\u001b[0m     \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   1800\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[0;32m   1801\u001b[0m         source, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[0;32m   1802\u001b[0m         memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1808\u001b[0m         page_checksum_verification\u001b[38;5;241m=\u001b[39mpage_checksum_verification,\n\u001b[0;32m   1809\u001b[0m     )\n\u001b[1;32m-> 1811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m                    \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1454\u001b[0m, in \u001b[0;36mParquetDataset.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   1446\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1447\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[0;32m   1448\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   1449\u001b[0m         ]\n\u001b[0;32m   1450\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1451\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[0;32m   1452\u001b[0m         )\n\u001b[1;32m-> 1454\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\_dataset.pyx:562\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\_dataset.pyx:3804\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\carola_luco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not open Parquet input source 'C:/Users/carola_luco/Sicredi/TimeBI_0730 - Documentos/01_Rotineiros/33_GiroCarteira/giro_de_carteira/bbmfiltros.py': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "principalidade =  pd.read_parquet(rf\"C:\\Users\\{user}\\Sicredi\\TimeBI_0730 - Documentos\\01_Rotineiros\\33_GiroCarteira\\giro_de_carteira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalidade"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
